{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tuning, Scoring, Evaluation.ipynb","provenance":[],"collapsed_sections":["Nbq_BhnyYtRO","_lIIaYJJvTBI","SL1uUDHniB2_","_aPLmyQQiCH_","2oR35v_MiCVX","_VyEGGpWoIfJ"],"authorship_tag":"ABX9TyMHr91UREt5diaUZ9/howI5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"Nbq_BhnyYtRO"}},{"cell_type":"code","source":["# script for standard imports\n","%run '/content/drive/MyDrive/Data_Science/scripts/setup.ipynb'"],"metadata":{"id":"RtWqNAxpZGs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trx_nc_prepped = \\\n","pd.read_csv('/content/drive/MyDrive/Data_Science/data/gtd/trx_nc_prepped.csv')\n","\n","trx_nc_prepped = \\\n","pd.read_csv('/content/drive/MyDrive/Data_Science/data/gtd/trainy.csv')"],"metadata":{"id":"ToL2WG-xYwLD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tuning model, Scoring & Evaluation\n","- Randomized Search and tuning parameters for selecting best model"],"metadata":{"id":"do1IasAGfMR_"}},{"cell_type":"code","source":["lr=LogisticRegression(random_state=33,n_jobs=-1)\n","tree=DecisionTreeClassifier(random_state=33)\n","forest=RandomForestClassifier(random_state=33,n_jobs=-1)\n","sgd=SGDClassifier(random_state=33,n_jobs=-1)"],"metadata":{"id":"MEVL1Cgqcbuv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Individual search spaces for each estimator (individual searches)"],"metadata":{"id":"_lIIaYJJvTBI"}},{"cell_type":"code","source":["logreg_grid = [{'penalty': ['l1', 'l2'],\n","                'C': np.logspace(0, 4, 10),\n","                'solver':['lbfgs', 'liblinear', 'sag', 'saga'],\n","                'class_weight':[None, 'balanced']}]"],"metadata":{"id":"jMWSEGancZl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dt_grid = [{'criterion': ['gini', 'entropy'],\n","            'max_depth': [5,10,20,None],\n","            'class_weight': [None, 'balanced'],\n","            'min_samples_split': [2,5,10],\n","            'max_features': ['auto', 'sqrt', 'log2'],\n","            'class_weight': [None, 'balanced']}]"],"metadata":{"id":"P329JdjAcg6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_grid = [{'n_estimators': [10, 50, 100, 200],\n","            'criterion': ['gini', 'entropy'],\n","            'max_depth': [5, 10, 20, None],\n","            'class_weight': [None, 'balanced'],\n","            'max_features': ['auto', 'sqrt', 'log2'],\n","            'bootstrap':[True,False]}]"],"metadata":{"id":"ryGVkAYXcioP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sgd_grid = [{'clf__class_weight':['balanced', None],\n","             'clf__penalty': ['l1','l2'],\n","             'clf__early_stopping': [True, False]}]"],"metadata":{"id":"gy7OuuN2ckLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" \"\"\"complete grid all models\"\"\"\n","    # param_grid = [{'clf': [lr],\n","    #             'clf__penalty': ['l1', 'l2'],\n","    #             'clf__C': np.logspace(0, 4, 10),\n","    #             'clf__solver':['lbfgs', 'liblinear', 'sag', 'saga'],\n","    #             'clf__class_weight':[None, 'balanced']},\n","    #             {'clf':[tree],\n","    #             'clf__criterion': ['gini', 'entropy'],\n","    #             'clf__max_depth': [5,10,20,None],\n","    #             'clf__class_weight': [None, 'balanced'],\n","    #             'clf__min_samples_split': [2,5,10],\n","    #             'clf__max_features': ['auto', 'sqrt', 'log2'],\n","    #             'clf__class_weight': [None, 'balanced']},\n","    #             {'clf': [forest],\n","    #             'clf__n_estimators': [10, 50, 100, 200],\n","    #             'clf__criterion': ['gini', 'entropy'],\n","    #             'clf__max_depth': [5, 10, 20, None],\n","    #             'clf__class_weight': [None, 'balanced'],\n","    #             'clf__max_features': ['auto', 'sqrt', 'log2'],\n","    #             'clf__bootstrap':[True,False]},\n","    #             {'clf': [sgd],\n","    #             'clf__class_weight':['balanced', None],\n","    #             'clf__penalty': ['l1','l2'],\n","    #             'clf__early_stopping': [True, False]}]"],"metadata":{"id":"JGzUZ-B7wqfH","executionInfo":{"status":"ok","timestamp":1653111786084,"user_tz":360,"elapsed":200,"user":{"displayName":"John E","userId":"00322197014987294418"}},"colab":{"base_uri":"https://localhost:8080/","height":37},"outputId":"3994e68a-da29-48d0-c91f-6837172347aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'complete grid all models'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":92}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"uKUzQIhAfbPH"}},{"cell_type":"code","source":["# # classification scoring metrics\n","# clf_metrics = [accuracy_score,precision_score,\n","#                recall_score,f1_score]"],"metadata":{"id":"TxvFfwo1tq0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Execute Randomized Search (per model)"],"metadata":{"id":"Nvmt67RFvXlJ"}},{"cell_type":"markdown","source":["###Logisitic Regression"],"metadata":{"id":"DenijkKbg7lf"}},{"cell_type":"code","source":["# cross-val method for model score/eval\n","cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"],"metadata":{"id":"kA0u4kiKQQqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr.get_params().keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AaJS2txOOXTq","executionInfo":{"status":"ok","timestamp":1653113217808,"user_tz":360,"elapsed":1058,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"43fa0f1c-fe8d-46f3-ba4b-127f540901e0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["print(f'Randomized Search for Logisitic Regression:\\n\\n')\n","\n","# logreg_pipe=Pipeline([('model', lr)])\n","eval_methods=['accuracy','precision','recall','f1']\n","\n","logreg_grid = [{'penalty': ['l1', 'l2'],\n","                'C': np.logspace(0, 4, 10),\n","                'solver':['lbfgs', 'liblinear', 'sag', 'saga'],\n","                'class_weight':[None, 'balanced']}]\n","\n","#instantiate RSVC and fit to data\n","rsvc_logreg=[]\n","for metric in eval_methods:\n","    rsvc_logreg.append(\n","        RandomizedSearchCV(lr, logreg_grid, cv=cv, verbose=0,\n","                           scoring=metric,return_train_score=False,\n","                           n_jobs=-1).fit(trx_nc_prepped,trainy.values))\n","#fit/train\n","# rsvc_logreg.fit(trx_nc_prepped,trainy.values)\n","\n","# logisitic regression best parameters identified by rscv\n","# for each in rsvc_logreg:\n","#     for metric in eval_methods:\n","#         print(f'Logisitic regression best paramaters identified by rscv:\\n\\\n","#         for {metric}: {each.best_params_}}\\n\\n')\n","\"\"\"if above doesnt work try w/:\"\"\"\n","# for each in rsvc_logreg:\n","#     print(f'Logisitic regression best paramaters identified by rscv:\\n\\\n","#     {each.best_params_}}\\n\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6GJ3ryCc-4f","outputId":"5eccb0eb-c131-487f-8587-999fe4158417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Randomized Search for Logisitic Regression:\n","\n","\n"]}]},{"cell_type":"code","source":["lr_best_score_permetric=[]\n","lr_best_model_per_metric=[]\n","lr_feat_importances_per_metric=[]\n","logreg_mean_score_permetric=[]\n","logreg_std_score_permetric=[]\n","\n","for metric in eval_methods:\n","    for each in rsvc_logreg:\n","        # view/get best paramaters/model per score-metric\n","        lr_best_score_permetric.append(\n","            {metric: [each.best_score_]})\n","        lr_best_model_per_metric.append(\n","            {metric: [each.best_estimator_]})\n","        lr_feat_importances_per_metric.append(\n","            {metric:[each.best_estimator_.feature_importances_]})\n","        \"\"\"nested CV\"\"\"\n","        #mean score per metric for best model\n","        logreg_mean_score_permetric.append((str(metric)+'_mean', \n","                                  cross_val_score(each, trx_nc_prepped, \n","                                  trainy.values, scoring=metric).mean()))\n","        #standard-dev per metric for best model\n","        logreg_std_score_permetric.append((str(metric)+'_std',\n","                                 cross_val_score(each, trx_nc_prepped,\n","                                 trainy.values, scoring=metric).std()))"],"metadata":{"id":"6wq3eeZfVBr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view best model and its best score\n","for each_score, each_best in zip(lr_best_score_permetric,\n","                                 lr_best_model_per_metric):\n","    print(f'Logistic Regression \"best score\": {each_score}\\n')\n","    print(f'\\nLogistic Regression \"best estimator\": {each_best}')\n","    # print(grid.best_params_)"],"metadata":{"id":"XzH-Idd3NihT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the cv-score of model,\n","# as a function of candidate hp-values for [--hp of choice--]:\n","\"\"\"... used initially on gscv i.e. \"rsvc_logreg.grid_scores_\" ...\n","       so may not work on rscv?\"\"\"\n","rsvc_logreg_scores = [val.mean_validation_score for val in rsvc_logreg.grid_scores_]\n","plt.semilogx(\"HP-of-choice\", rsvc_logreg_scores)\n","plt.xlabel(\"hp-name\")\n","plt.ylabel('accuracy')\n","# 5'print(f'(default-score-setting) for Accuracy: {logreg_grid.best_params_)}')"],"metadata":{"id":"48HUt_yTVGDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decision Tree"],"metadata":{"id":"SL1uUDHniB2_"}},{"cell_type":"code","source":["print(f'Randomized Search for Decision Tree:\\n\\n')\n","\n","dt_pipe=Pipeline([('model', lr)])\n","metric_str_names=['accuracy','precision','recall','f1']\n","\n","#instantiate RSVC\n","rsvc_dt= \\\n","RandomizedSearchCV(dt_pipe, dt_grid, cv=3, verbose=0,\n","                   scoring=metric,return_train_score=False,\n","                   n_jobs=-1))\n","\n","#fit/train\n","rsvc_dt.fit(trx_nc_prepped,trainy.values)\n","\n","# view items\n","# rsvc_dt.get_params().keys()\n","\n","# Decision Tree best paramaters identified by rscv\n","print(f'Decision Tree best paramaters identified by rscv:\\n\\\n","{rsvc_dt.best_params_}\\n\\n')\n","\"\"\"if above doesnt work try w/:\"\"\"\n","# print(f'Decision Tree best paramaters identified by rscv:\\n\\\n","# {dt_grid.best_params_}\\n\\n')\n","\n","\n","# nested CV\n","dt_mean_score=[]\n","dt_std_score=[]\n","for metric in metric_str_names:\n","    #mean score per metric for best model\n","    dt_mean_score.append((str(metric)+'_mean', \n","            cross_val_score(rsvc_dt trx_nc_prepped, \n","                            trainy.values, scoring=metric).mean()))\n","    #standard-dev per metric for best model\n","    dt_std_score.append((str(metric)+'_std',\n","            cross_val_score(rsvc_dt trx_nc_prepped, \n","                            trainy.values, scoring=metric).std()))\n","# view/get best paramaters/model per score-metric\n","dt_best_score=[]\n","dt_best_model=[]\n","# features_importances=[]\n","\n","for metric in metric_str_names:\n","    dt_best_score.append({metric: [rsvc_dt.best_score_]})\n","    dt_best_model.append({metric: [rsvc_dt.best_estimator_]})\n","    # features_importances.append({metric:[each.best_estimator_.feature_importances_]})\n","\n","# view\n","print(f'Decision Tree \"best score\": {dt_best_score}\\n')\n","print(f'\\nDecision Tree \"best estimator\": {dt_best_model}')\n","\n","# plot the cv-score of model,\n","# as a function of candidate hp-values for [--hp of choice--]:\n","\"\"\"... used initially on gscv i.e. \"rsvc_logreg.grid_scores_\" ...\n","       so may not work on rscv?\"\"\"\n","rsvc_dt_scores = [val.mean_validation_score for val in rsvc_dt.grid_scores_]\n","plt.semilogx(\"HP-of-choice\", rsvc_dt_scores)\n","plt.xlabel(\"hp-name\")\n","plt.ylabel('accuracy')\n","# print(f'(default-score-setting) for Accuracy: {rsvc_dt.best_params_)}')"],"metadata":{"id":"Ep2hUiPdiB8H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Random Forest\n"],"metadata":{"id":"_aPLmyQQiCH_"}},{"cell_type":"code","source":["print(f'Randomized Search for Random Forest:\\n\\n')\n","\n","rf_pipe=Pipeline([('model', lr)])\n","metric_str_names=['accuracy','precision','recall','f1']\n","\n","#instantiate RSVC\n","rsvc_rf = \\\n","RandomizedSearchCV(rf_pipe, rf_grid, cv=3, verbose=0,\n","                   scoring=metric,return_train_score=False, n_jobs=-1))\n","#fit/train\n","rsvc_rf.fit(trx_nc_prepped,trainy.values)\n","\n","# view all parameters\n","# rsvc_rf.get_params().keys()\n","\n","# Random Forest best paramaters identified by rscv\n","print(f'Random Forest best paramaters identified by rscv:\\n\\\n","{rsvc_rf.best_params_}\\n\\n')\n","\"\"\"if above doesnt work try w/:\"\"\"\n","# print(f'Decision Tree best paramaters identified by rscv:\\n\\\n","# {rf_grid.best_params_}\\n\\n')\n","\n","# nested CV\n","rf_mean_score=[]\n","rf_std_score=[]\n","for metric in metric_str_names:\n","    #mean score per metric for best model\n","    rf_mean_score.append((str(metric)+'_mean', \n","            cross_val_score(rsvc_rf, trx_nc_prepped, \n","                            trainy.values, scoring=metric).mean()))\n","    #standard-dev per metric for best model\n","    rf_std_score.append((str(metric)+'_std',\n","            cross_val_score(rsvc_rf, trx_nc_prepped, \n","                            trainy.values, scoring=metric).std()))\n","# view/get best paramaters/model per score-metric\n","rf_best_score=[]\n","rf_best_model=[]\n","# features_importances=[]\n","\n","for metric in metric_str_names:\n","    rf_best_score.append({metric: [rsvc_rf.best_score_]})\n","    rf_best_model.append({metric: [rsvc_rf.best_estimator_]})\n","    # features_importances.append({metric:[each.best_estimator_.feature_importances_]})\n","\n","# view\n","print(f'Random Forest \"best score\": {rf_best_score}\\n')\n","print(f'\\nRandom Forest \"best estimator\": {rf_best_model}')\n","\n","# plot the cv-score of model,\n","# as a function of candidate hp-values for [--hp of choice--]:\n","\"\"\"... used initially on gscv i.e. \"rsvc_logreg.grid_scores_\" ...\n","       so may not work on rscv?\"\"\"\n","rsvc_rf_scores = [val.mean_validation_score for val in rsvc_rf.grid_scores_]\n","plt.semilogx(\"HP-of-choice\", rsvc_rf_scores)\n","plt.xlabel(\"hp-name\")\n","plt.ylabel('accuracy')\n","# print(f'(default-score-setting) for Accuracy: {rsvc_dt.best_params_)}')"],"metadata":{"id":"SItrkfn4iCNH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SGD"],"metadata":{"id":"2oR35v_MiCVX"}},{"cell_type":"code","source":["print(f'Randomized Search for Stochastic Gradient Descent (SGD):\\n\\n')\n","\n","sgd_pipe=Pipeline([('model', lr)])\n","metric_str_names=['accuracy','precision','recall','f1']\n","\n","#instantiate RSVC\n","rsvc_sgd = \\\n","RandomizedSearchCV(sgd_pipe, sgd_grid, cv=3, verbose=0,\n","                   scoring=metric,return_train_score=False,\n","                   n_jobs=-1))\n","\n","#fit/train\n","rsvc_sgd.fit(trx_nc_prepped,trainy.values)\n","\n","# view items\n","# >>> rsvc_sgd.get_params().keys()\n","\n","# SGD best paramaters identified by rscv\n","print(f'SGD best paramaters identified by rscv:\\n\\\n","{rsvc_sgd.best_params_}\\n\\n')\n","\"\"\"if above doesnt work try w/:\"\"\"\n","# print(f'Decision Tree best paramaters identified by rscv:\\n\\\n","# {sgd_grid.best_params_}\\n\\n')\n","\n","# nested CVsgd_mean_score=[]sgd_std_score=[]\n","for metric in metric_str_names:\n","    #mean score per metric for best model\n","sgd_mean_score.append((str(metric)+'_mean', \n","            cross_val_score(rsvc_sgd, trx_nc_prepped, \n","                            trainy.values, scoring=metric).mean()))\n","    #standard-dev per metric for best model\n","sgd_std_score.append((str(metric)+'_std',\n","            cross_val_score(rsvc_sgd, trx_nc_prepped, \n","                            trainy.values, scoring=metric).std()))\n","# view/get best paramaters/model per score-metric\n","sgd_best_score=[]\n","sgd_best_model=[]\n","# features_importances=[]\n","\n","for metric in metric_str_names:#, rsvc_sgd):\n","    sgd_best_score.append({metric: [rsvc_sgd.best_score_]})\n","    sgd_best_model.append({metric: [rsvc_sgd.best_estimator_]})\n","    # features_importances.append({metric:[each.best_estimator_.feature_importances_]})\n","\n","# view\n","print(f'SGD \"best score\": {sgd_best_score}\\n\\n')\n","print(f'\\SGD \"best estimator\": {sgd_best_model}')\n","\n","# plot the cv-score of model,\n","# as a function of candidate hp-values for [--hp of choice--]:\n","\"\"\"... used initially on gscv i.e. \"rsvc_logreg.grid_scores_\" ...\n","       so may not work on rscv?\"\"\"\n","rsvc_sgd_scores = [val.mean_validation_score for val in rsvc_sgd.grid_scores_]\n","plt.semilogx(\"HP-of-choice\", rsvc_sgd_scores)\n","plt.xlabel(\"hp-name\")\n","plt.ylabel('accuracy')\n","# print(f'(default-score-setting) for Accuracy: {rsvc_sgd.best_params_)}') # or try sgd_grid"],"metadata":{"id":"BB_M6frJiCaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIN2477Lz4er"},"outputs":[],"source":["\"\"\" ---------------------Here for Reference------------------------\"\"\"\n","\n","    # # -------------Feature Selection----------------------------------------\n","        # from sklearn.feature_selection import  chi2, f_classif, mutual_info_classif\n","\n","\n","    # # -------------- Dimensionality Reduction ------------------------------\n","        # from sklearn.decomposition import (PCA, KernelPCA,\n","        #                                    IncrementalPCA, \n","        #                                    NMF, TruncatedSVD)\n","        # from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","\n","\n","    # # ----------------- Reg/Classif Algorithms --------------------------\n","        # from sklearn.linear_model import SGDRegressor, SGDClassifier\n","        # from sklearn.linear_model import LinearRegression, LogisticRegression\n","        # from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","        # from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","        # from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n","        # from sklearn.svm import LinearSVR, SVR, LinearSVC, SVC\n","\n","\n","    # #-------------------- Model Scoring/Evaluation -------------------------\n","        # from sklearn.metrics import (accuracy_score,\n","        #                              precision_score,\n","        #                              recall_score,\n","        #                              f1_score,\n","        #                              mean_squared_error,\n","        #                              mean_absolute_error,\n","        #                              make_scorer,\n","        #                              confusion_matrix,\n","        #                              precision_recall_curve,\n","        #                              auc,\n","        #                              roc_curve,\n","        #                              roc_auc_score,\n","        #                              mutual_info_score,\n","        #                              multilabel_confusion_matrix)\n","\n","\n","    # #-------------------- Model Selection ---------------------------------\n","        # from sklearn.dummy import DummyClassifier\n","        # from sklearn.model_selection import cross_validate\n","        # from sklearn.model_selection import cross_val_score\n","        # from sklearn.model_selection import cross_val_predict\n","        # from sklearn.model_selection import learning_curve\n","        # from sklearn.model_selection import validation_curve\n","        # from sklearn.model_selection import permutation_test_score\n","        # from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","        # from sklearn.model_selection import ParameterGrid\n","        # from sklearn.model_selection import ParameterSampler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVH2uuJj7B7h"},"outputs":[],"source":["\"\"\"Linear Regression modeling process examples\"\"\"\n","\n","    # \"\"\"LR\"\"\"\n","    #     # lrclf.fit(trx_nc_prepped, train_y)\n","    #     # lrclf_preds = lrclf.predict(trx_nc_prepped)\n","    #     # lrclf_mse = mean_squared_error(train_y, lrclf_preds)\n","    #     # lrclf_rmse = np.sqrt(lrclf_mse)\n","    #     # lrclf_mae = mean_absolute_error(housing_labels, housing_predictions)\n","    # \"\"\"tree\"\"\"\n","    #     # tree_reg.fit(housing_prepared, housing_labels)\n","    #     # housing_predictions = tree_reg.predict(housing_prepared)\n","    #     # tree_mse = mean_squared_error(housing_labels, housing_predictions)\n","    #     # tree_rmse = np.sqrt(tree_mse)\n","    # \"\"\"forest\"\"\"\n","    #     # forest_reg.fit(housing_prepared, housing_labels)\n","    #     # housing_predictions = forest_reg.predict(housing_prepared)\n","    #     # forest_mse = mean_squared_error(housing_labels, housing_predictions)\n","    #     # forest_rmse = np.sqrt(forest_mse)\n","    # \"\"\"SVector\"\"\"\n","    #     # svc.fit(housing_prepared, housing_labels)\n","    #     # housing_predictions = svc.predict(housing_prepared)\n","    #     # svc_mse = mean_squared_error(housing_labels, housing_predictions)\n","    #     # svc_rmse = np.sqrt(svm_mse)"]},{"cell_type":"markdown","metadata":{"id":"_VyEGGpWoIfJ"},"source":["## (alternative) GSCV approach"]},{"cell_type":"code","source":["# Individual example GridSearchCV/RandomizedSearchCV\n","# >>> clf = GridSearchCV(algo_pipe, param_grid, cv=5, verbose=0, \n","# >>>                    return_train_score=False, n_jobs=-1)\n","\n","# >>> rscv = RandomizedSearchCV(algo_pipe, param_grid, cv=5, verbose=0, \n","# >>>                           return_train_score=False, n_jobs=-1)\n","\n","\"\"\"# add into grid search to expand\"\"\"\n","# RidgeClassifier(tol=1e-2, solver=\"sag\")\n","# Perceptron(max_iter=50)\n","# # PassiveAggressiveClassifier(max_iter=50) ??\n","# KNeighborsClassifier(n_neighbors=10)\n","\n","# # LinearSVC with L1-based feature selection\n","# # -- The smaller C, the stronger the regularization.\n","# # -- The more regularization, the more sparsity.\n","# LinearSVC(penalty='l1' dual=False, tol=1e-3)\n","\n","# SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\")\n","\n","# #\"NearestCentroid (aka Rocchio classifier)\n","# NearestCentroid()\n","\n","# # Naive Bayes models\n","# MultinomialNB(alpha=.01)\n","# BernoulliNB(alpha=.01)\n","# ComplementNB(alpha=.1)"],"metadata":{"id":"DE7maAOd2F4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \"\"\"EXAMPLE\"\"\"\n","# params = {'n_estimators':[10,50,100,250],\n","#           'max_depth':[5,10,20],\n","#           'class_weight':[None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]}\n","\n","# forest_example = RandomForestClassifier(random_state=42)\n","# gs = GridSearchCV(forest_example, params, scoring='roc_auc', n_jobs=-1)\n","# gs.fit(X_train, y_train)\n","\n","# print(\"Best set of Parameters\",gs.best_params_)\n","# print(\"Best Score\",gs.best_score_)"],"metadata":{"id":"L0mgry_ykZrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #numeric pipe\n","# nprep_pipe = Pipeline(\n","#     [(\"n_imp\", SimpleImputer(strategy='median')),\n","#     ('n_ssscale', MinMaxScaler()),\n","#     ('n_collin_remove_90', CollinearRemover(collinear_cutoff=.90))])\n","\n","# #categoric pipe\n","# cprep_pipe = Pipeline(\n","#     [('c_imp', SimpleImputer(strategy='constant',fill_value='missing')),\n","#     ('c_hash_enc', ce.HashingEncoder(drop_invariant=True)),\n","#     ('c_collin_remove_95', CollinearRemover(collinear_cutoff=.95))])\n","\n","\n","# ncols, ccols, tcols = \\\n","# list(ncols.cols), list(ccols.cols), list(tcols.cols)\n","\n","# #build heterogeneous prep pipeline \n","# ncprep_pipe = \\\n","# ColumnTransformer([('nprep', nprep_pipe, ncols),\n","#                    ('cprep', cprep_pipe, ccols)])\n","\n","# # train pipeline\n","# # >>> ncprep_pipe.fit(trx_opt)\n","\n","# # and prepare numeric/categoric data for ml \n","# # >>>trx_nc_prepped = ncprep_pipe.transform(trx_opt)"],"metadata":{"id":"6Wm1hO-zaqY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZceDa55v3Js"},"outputs":[],"source":["# # Create estimator pipeline\n","# pipe = Pipeline([('prep', ncprep_pipe),('clf', lr)])\n","\n","# # Create space of algorithms and their hyperparameters\n","# param_grid = [{'clf': [lr],\n","#                'clf__penalty': ['l1', 'l2'],\n","#                'clf__C': np.logspace(0, 4, 10),\n","#                'clf__solver':['lbfgs', 'liblinear', 'sag', 'saga'],\n","#                'clf__class_weight':[None, 'balanced']},\n","#               {'clf':[tree],\n","#                'clf__criterion': ['gini', 'entropy'],\n","#                'clf__max_depth': [5,10,20,None],\n","#                'clf__class_weight': [None, 'balanced'],\n","#                'clf__min_samples_split': [2,5,10],\n","#                'clf__max_features': ['auto', 'sqrt', 'log2'],\n","#                'clf__class_weight': [None, 'balanced']},\n","#               {'clf': [forest],\n","#                'clf__n_estimators': [10, 50, 100, 200],\n","#                'clf__criterion': ['gini', 'entropy'],\n","#                'clf__max_depth': [5, 10, 20, None],\n","#                'clf__class_weight': [None, 'balanced'],\n","#                'clf__max_features': ['auto', 'sqrt', 'log2'],\n","#                'clf__bootstrap':[True,False]},\n","#               {'clf': [sgd],\n","#                'clf__class_weight':['balanced', None],\n","#                'clf__penalty': ['l1','l2'],\n","#                'clf__early_stopping': [True, False]}]\n","\n","# # eval individual estimators:\n","\n","# for metric, model in zip(eval_method, clf_models):\n","#     GridSearchCV(model, param_grid, cv=5, scoring=metric)\\\n","#                         .fit(trx_nc_prepped, trainy)\n","\n","#     print(f\"Best parameters:\\n{clf.best_params_}\")\n","#     print(f\"\\nGridSearch Mean test scores:\\n\\\n","#     {clf.cv_results_['mean_test_score']}\")\n","#     print(f\"\\nGridSearch std test scores:\\n\\\n","#     {clf.cv_results_['std_test_score']}\")\n","#     # for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","#     #     print(\"%s (+/-%s) for %s\" % (mean, std * 2, params))"]},{"cell_type":"code","source":["# rscv = RandomizedSearchCV(pipe, param_grid,\n","#                           cv=3, verbose=0,\n","#                           return_train_score=False, n_jobs=-1)\n","# # fit/train\n","# rscv.fit(trx_nc_prepped,trainy.values)\n","# #>>> print(f\"\\nBest model parameters:\\n{rscv.best_estimator_.get_params()['clf']}\")\n","# print(f'Best model-parameters:\\n{rscv.best_params_}') # Alternative\n","# print(f'\\nBest model score:\\n{rscv.best_score_}')\n","# print(f'\\nBest model feature Importances:\\n\\\n","# {rscv.best_estimator_.feature_importances_}')\n","\n","# best_model = rscv.best_estimator_"],"metadata":{"id":"RVamm1VXiFvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rscvs=[]\n","# for metric in metric_str_names:\n","#     rscvs.append(\n","#             RandomizedSearchCV(\n","#                 algo_pipe, param_grid, \n","#                 cv=3, verbose=0, scoring=metric,\n","#                 return_train_score=False, n_jobs=-1).fit(trx_nc_prepped,\n","#                                                          trainy.values))\n","# best_models = []\n","# for each in rscvs:\n","#     best_models.append(each.best_estimator_)\n","\n","# # Let's look at the score of each hp-combo tested:\n","# >>> gscv_res = gscv.cv_results_\n","# >>> for mean_score, params in zip(gscv_res[\"mean_test_score\"],\n","# >>>                               gscv_res[\"params\"]):\n","    \n","# >>>     print(np.sqrt(-mean_score), params)\n","\n","# >>> rscv_feature_importances = rnd_search.best_estimator_.feature_importances_\n","# >>> rscv_feature_importances"],"metadata":{"id":"RN_RYDpO7Rog"},"execution_count":null,"outputs":[]}]}