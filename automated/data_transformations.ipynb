{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data transformations.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lR2ZsqmUhyy_",
        "xiYwU-1suZ14"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Previous notebooks, and completed processes:\n",
        "\n",
        "_\"preprocessing.ipynb\"_\n",
        "- 1. Initial data adjustments\n",
        "- 2. Preprocessing\n",
        "\n",
        "_\"baseline scores after preproc.ipynb\"_\n",
        "\n",
        "- Establish baseline scores"
      ],
      "metadata": {
        "id": "rDT5kfo7aNOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setup"
      ],
      "metadata": {
        "id": "lR2ZsqmUhyy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# script for standard imports\n",
        "%run '/content/drive/MyDrive/Data_Science/scripts/setup.ipynb'\n",
        "\n",
        "# read-in data (\"trx_preproc\" represents the preprocessed trainx data)\n",
        "trx_preproc = \\\n",
        "pd.read_csv('/content/drive/MyDrive/Data_Science/data/gtd/trx_preproc.csv')"
      ],
      "metadata": {
        "id": "1s2jkX42hx3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Data transformations \n",
        "_(numeric/categoric only)_\n",
        "\n",
        "3.0.1 : `select_cols_for_pipe`\n",
        "- Column Selection for Pipelines: creating explicit lists per dtype for sklearn pipeline (next notebook, \"transformations\")\n",
        "\n",
        "3.0.2 : Build transformation pipelines\n",
        "- Impute, encode, scale and removing excessive features that are highly collinear\n",
        "\n",
        "3.0.3 : Combine numeric/categoric preparation pipelines\n",
        "- Build/train heterogeneous pipeline on preprocessed data and execute transforms"
      ],
      "metadata": {
        "id": "xiYwU-1suZ14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.0.1 : `select_cols_for_pipe` - Column Selection for pipelines"
      ],
      "metadata": {
        "id": "CEvpGS7nzntB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug4wzxtcat8x"
      },
      "outputs": [],
      "source": [
        "# run script for simple function that uses\n",
        "# `ColumnSelector` transformer to get columns per dtype\n",
        "%run '/content/drive/MyDrive/Data_Science/modules/gtd/select_cols_for_pipe.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BihR_Jgl6Or",
        "outputId": "1b8d7786-0610-4557-a2ac-214122774662"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mlxtend.feature_selection.column_selector.ColumnSelector"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mlxtend.feature_selection.column_selector.ColumnSelector"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mlxtend.feature_selection.column_selector.ColumnSelector"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "ncols,ccols,tcols = select_cols_for_pipe(trx_preproc)\n",
        "\n",
        "# view ColumnSelector objects\n",
        "display(type(ncols),type(ccols),type(tcols))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obe9hdxQm0xC"
      },
      "source": [
        "We can use the ColumnSelector-transformers objects above, as is, for an individual step of a pipeline. For simplicity, lets just establish the feature-lists from them for now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjSaYR8rnIUy",
        "outputId": "c6542d42-57c7-43d2-edd4-3a1531016b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total features per dtype:\n",
            "numeric: 31\n",
            "categoric:30\n",
            "text:4\n"
          ]
        }
      ],
      "source": [
        "ncols, ccols, tcols = \\\n",
        "list(ncols.cols), list(ccols.cols), list(tcols.cols)\n",
        "\n",
        "print(f'Total features per dtype:\\n\\\n",
        "numeric: {len(ncols)}\\ncategoric:{len(ccols)}\\ntext:{len(tcols)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW5fVnFDj0DT"
      },
      "source": [
        "3.0.2 : Build pipelines for standard data transformations, for numeric/categoric training data\n",
        "- _Impute, encode, scale and removing excessive features that are highly collinear_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlFknL0YjdWr"
      },
      "outputs": [],
      "source": [
        "# run script for simple feature-selection \n",
        "# function for removing data with high cardinality\n",
        "%run '/content/drive/MyDrive/Data_Science/modules/gtd/CollinearRemover.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaSQ4LoFarNa"
      },
      "outputs": [],
      "source": [
        "#numeric pipe\n",
        "nprep_pipe = Pipeline(\n",
        "    [(\"n_imp\", SimpleImputer(strategy='median')),\n",
        "    ('n_ssscale', MinMaxScaler()),\n",
        "    ('n_collin_remove_90', CollinearRemover(collinear_cutoff=.90))])\n",
        "\n",
        "#categoric pipe\n",
        "cprep_pipe = Pipeline(\n",
        "    [('c_imp', SimpleImputer(strategy='constant',fill_value='missing')),\n",
        "    ('c_hash_enc', ce.HashingEncoder(drop_invariant=True)),\n",
        "    ('c_collin_remove_95', CollinearRemover(collinear_cutoff=.95))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_nz7wQtp5Zy"
      },
      "source": [
        "3.0.3 : Combine preparation pipelines\n",
        "- _Build/train heterogeneous pipeline on preprocessed data and execute transforms_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH3s2G8ayZl6",
        "outputId": "73ac17b9-019b-4eba-fdd0-7c8198128909"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153171, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trx_preproc.shape #reminder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kchCROnDyMZi"
      },
      "outputs": [],
      "source": [
        "#build heterogeneous prep pipeline \n",
        "ncprep_pipe = \\\n",
        "ColumnTransformer([('nprep', nprep_pipe, ncols),\n",
        "                   ('cprep', cprep_pipe, ccols)])\n",
        "# train pipeline,\n",
        "ncprep_pipe.fit(trx_preproc)\n",
        "\n",
        "# prepare (numeric/categoric) data for ml \n",
        "trx_prepped = ncprep_pipe.transform(trx_preproc)\n",
        "\n",
        "# view results after data transformations (n&c only)\n",
        "trx_prepped.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write transformed data (num/cat only), \"trx_prepped\", to csv\n",
        "trx_prepped.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trx_prepped.csv',\n",
        "                   index=False)"
      ],
      "metadata": {
        "id": "EqrVOcG6WylQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps"
      ],
      "metadata": {
        "id": "POUmEtbCbQ-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning and model evaluation (see, _\"tuning, scoring, evaluation.ipynb\"_)."
      ],
      "metadata": {
        "id": "aw2VhhrrcnC4"
      }
    }
  ]
}