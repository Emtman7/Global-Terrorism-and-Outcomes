{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"early stage preprocessing.ipynb","provenance":[],"collapsed_sections":["GLqXSQ7dgSQc"],"authorship_tag":"ABX9TyOiRUmA6eq9DRtlh4YA1jiv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GLqXSQ7dgSQc"},"source":["# setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22PHePfWhagv"},"outputs":[],"source":["# script for standard imports and reading gtd_df.csv\n","%run '/content/drive/MyDrive/Data_Science/scripts/setup_get_gtd_data.ipynb'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1653111102967,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"FszPO709_4Hy","outputId":"0d603955-5782-4cdd-eb84-02f7ae6bc53a"},"outputs":[{"output_type":"stream","name":"stdout","text":["admin_enc_col_df\t admin_enc_df\t cols_for_later\t data\t df\t eventid_related_df\t lat_long_df\t test_x\t testx\t \n","train_x\t trainx\t trx_cats\t trx_cats_opt\t trx_floats\t trx_floats_opt\t trx_ints\t trx_ints_opt\t trx_non_txt\t \n","trx_opt\t trx_preproc\t trx_replaced\t trx_replaced_merged\t trx_txt\t x\t \n"]}],"source":["%who DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1653111102968,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"CE72tqV1PAcs","outputId":"6891675a-8632-49a6-87c7-29661704b280"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(191464, 135)"]},"metadata":{},"execution_count":47}],"source":["x = df.copy()\n","x.shape"]},{"cell_type":"markdown","source":["# Get Data ready for ML\n","- simple adjustments, preprocessing, transformations"],"metadata":{"id":"q1Q-ycXpvuIT"}},{"cell_type":"markdown","metadata":{"id":"yEn9RT-yoNIa"},"source":["## Step 1: Early-stage data adjustments \n","- (b4 preproc/transforms; num/cat only)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikLyTU2IO6dl"},"outputs":[],"source":["# get all DB admin encoded columns\n","admin_enc_df = \\\n","x.loc[:, [c for c in \n","        [c[:-4] for c in x if '_txt' in c]\n","        if c in x]]\n","\n","#save for comparison or later usage\n","admin_enc_col_list = list(admin_enc_df.columns)\n","# build admin_enc_col_df\n","admin_enc_col_df = x.loc[:, admin_enc_col_list]\n","\n","# do the same w/ lat and long \n","# (add back to dataset later if wanted)\n","lat_long_df=x.loc[:, ['latitude','longitude']]\n","\n","# combine into single column (for dt) create\n","'''to use: .astype('datetime') on \"datetime_col\",\n","need to fill '0' first at all locs'''\n","\n","datetime_col = x['iday'].astype('string') + '-' \\\n","+ x['imonth'].astype('string') + '-' \\\n","+ x['iyear'].astype('string')\n","\n","# remove original day,month,year cols\n","x = x.drop(['iday','imonth','iyear'], axis=1)\n","\n","\"\"\" STEP #1 : Data-Type Adjustments \"\"\"\n","# # Adjust to string Dtypes for text\n","txt_col_list = \\\n","['motive', 'summary','location','propcomment']\n","\n","x.loc[:, txt_col_list] = \\\n","x.loc[:, txt_col_list].astype('string')\n","\n","x['d_m_y'] = datetime_col\n","\n","eventid_related_df = \\\n","x.loc[:, ['eventid', 'related', 'dbsource']]\n","\n","# \"\"\"Get \"cols_for_later\" : \"\"\"\n","cols_for_later = pd.concat(\n","    [x['d_m_y'], lat_long_df, eventid_related_df], axis=1)"]},{"cell_type":"markdown","source":["1.0 : drop admin encoded cols and additional cols (for later analysis)"],"metadata":{"id":"wEpuHU7Mwlbg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"791XJu2pRwyh"},"outputs":[],"source":["# drop admin encoded cols\n","x = x.drop(list(admin_enc_col_list), axis=1)\n","# Drop additional cols (for later analysis)\n","x = x.drop(list(cols_for_later),axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84,"status":"ok","timestamp":1653111104487,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"loSMpU7kR_BI","outputId":"9ed2a661-0cff-478f-a5ea-8b1a70e8cb89"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(191464, 99)"]},"metadata":{},"execution_count":50}],"source":["x.shape"]},{"cell_type":"markdown","metadata":{"id":"aSm7S9VmoWM6"},"source":["1.1 : Get X train/test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3MkUgYaOO-A"},"outputs":[],"source":["data = x.copy()\n","\n","SSS = StratifiedShuffleSplit(n_splits=1,\n","                              test_size=0.2,\n","                              random_state=3)\n"," \n","for train_idx, test_idx in SSS.split(data, \n","                                     data['success']):\n","    # train and test sets\n","    train_x = data.iloc[train_idx, :]\n","    test_x = data.iloc[test_idx, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1653111105272,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"IobrtBOpSJqA","outputId":"520ae36e-58ec-4ddb-ca44-f651e88f32ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((153171, 99), (38293, 99))"]},"metadata":{},"execution_count":52}],"source":["train_x.shape, test_x.shape"]},{"cell_type":"markdown","metadata":{"id":"LplC-rkEgCmF"},"source":["1.3 : Remove rows/columns with very high NaN-counts"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1288,"status":"ok","timestamp":1653111106508,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"MqyLLXeHbfvQ","outputId":"22b9cbe1-ca6b-46ff-b5f0-5958aeb8ad2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set (trainx) contains 33 variables with >= 0.95% NaNs\n","\n","\"train_x\" shape after removing columns w/ >= 95% NaNs: (153171, 66)\n"]}],"source":["#remove rows/columns with very high NaN-counts\n","trx_nan_perc = train_x.isnull().sum() / len(train_x)\n","\n","#condition\n","thresh=0.95\n","thresh_nans = trx_nan_perc>=thresh\n","\n","#subset\n","print(f'Training set (trainx) contains \\\n","{len(trx_nan_perc[thresh_nans])} variables with >= {thresh}% NaNs\\n')\n","\n","# view cols w/ large % Nans\n","high_nan_vars = trx_nan_perc[thresh_nans]\n","high_nan_vars.sort_values(ascending=False)\n","\n","# remove cols w/ high NaN percentages from train set\n","# (save for later for other NaN-alternatives after initial run)\n","train_x.loc[:, list(high_nan_vars.index)]\\\n",".to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trainx_high_nans.csv')\n","\n","# Remove Columns with large percentage of NaNs\n","train_x = train_x.drop(list(high_nan_vars.index),axis=1)\n","\n","# trainx updated\n","print(f'\"train_x\" shape after removing columns w/ >= 95% NaNs: {train_x.shape}')"]},{"cell_type":"markdown","metadata":{"id":"jgxRPw_DTapv"},"source":["## Step 2: Preprocess, Prepare/Transform (num/cat only)"]},{"cell_type":"markdown","source":["2.0: Establish X/y sets and drop target from train/testx sets"],"metadata":{"id":"0o7I-cDNwCcA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZjfQQBiSR2T"},"outputs":[],"source":["# establish \"target\"\n","trainy = train_x[\"success\"]\n","testy = test_x['success']\n","\n","# and drop from X sets\n","trainx = train_x.drop('success', axis=1)\n","testx = test_x.drop('success', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1653111106510,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"iLMvPqGdSsYI","outputId":"805e903b-a731-460f-bb5b-44eb810bb5ea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((153171,), (38293,))"]},"metadata":{},"execution_count":55}],"source":["# view train/test sets for target\n","trainy.shape, testy.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144,"status":"ok","timestamp":1653111106511,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"IgJaFVCjVezd","outputId":"eb583d2c-0ea3-4c30-a51b-24e384a25557"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((153171, 65), (153171,))"]},"metadata":{},"execution_count":56}],"source":["#view X-sets after target removal\n","trainx.shape, trainy.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1653111106512,"user":{"displayName":"John E","userId":"00322197014987294418"},"user_tz":360},"id":"8bXVf8jtXb4p","outputId":"c82a6de2-fc9e-4079-a726-a6059af4d72e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["object     30\n","float64    17\n","int64      14\n","string      4\n","dtype: int64"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 153171 entries, 59924 to 95773\n","Columns: 65 entries, approxdate to INT_ANY\n","dtypes: float64(17), int64(14), object(30), string(4)\n","memory usage: 77.1+ MB\n"]}],"source":["#before dtype adjustments\n","display(pd.Series(trainx.dtypes).value_counts())\n","trainx.info(verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"qvDsbzF5o3Fb"},"source":["2.1: optimize dtypes on training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"buNpdYqPXA8p"},"outputs":[],"source":["# Reminder to back astype(\"U\") b4 tfidf\n","trx_txt = trainx.select_dtypes(include='string') \n","trx_non_txt = trainx.select_dtypes(exclude='string')\n","# optimize object-types (categorical)\n","trx_cats = trx_non_txt.select_dtypes(object)\n","trx_cats_opt = optimize_objects(trx_cats)\n","# optimize int-types\n","trx_ints = trx_non_txt.select_dtypes(int)\n","trx_ints_opt = optimize_ints(trx_ints)\n","# optimize float-types\n","trx_floats = trx_non_txt.select_dtypes(float)\n","trx_floats_opt = optimize_floats(trx_floats)\n","\n","trx_opt = pd.concat([trx_txt, trx_ints_opt,\n","                     trx_floats_opt, \n","                     trx_cats_opt], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"sf4E0zSxZAlY","executionInfo":{"status":"ok","timestamp":1653111277133,"user_tz":360,"elapsed":169146,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"23bef420-10bb-49e0-ca5d-787d221579d8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["object      29\n","float32     17\n","int8        14\n","string       4\n","category     1\n","dtype: int64"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 153171 entries, 59924 to 95773\n","Columns: 65 entries, location to scite3\n","dtypes: category(1), float32(17), int8(14), object(29), string(4)\n","memory usage: 53.3+ MB\n"]}],"source":["# trainx after dtype adjustments\n","display(pd.Series(trx_opt.dtypes).value_counts())\n","trx_opt.info(verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"gM_4OjX7ZNyz"},"source":["> _We've decreased the memory usage by about 24MB after dtype-optimization._"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyackKJIZij0","executionInfo":{"status":"ok","timestamp":1653111277134,"user_tz":360,"elapsed":107,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"3cd20f0a-5e75-4bd7-f8db-dce18f5408d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":60}],"source":["# without affecting the inherent training data:\n","set(trx_opt)==set(trainx)"]},{"cell_type":"markdown","metadata":{"id":"8GChkIflsz70"},"source":["2.2 : Expanding on initial data preprocessing \n","- including additional preprocessing operations with `replace_uppr_w_lower`, `merge_items`, `BuildBinaries`\n","- Next preprocessing steps need to be in sequence: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z77JYhtbtYwa"},"outputs":[],"source":["%run '/content/drive/MyDrive/Data_Science/modules/gtd/replace_uppr_w_lowr.ipynb'\n","%run '/content/drive/MyDrive/Data_Science/modules/gtd/merge_items.ipynb'\n","%run '/content/drive/MyDrive/Data_Science/modules/gtd/BuildBinaries.ipynb'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEl-9jRYux3r"},"outputs":[],"source":["# these were determined through early data exploration (diff nb)\n","missing_labels = ['Unknown',-9,-99]\n","make_lower = 'Unknown'\n","merge_labels = True\n","merge_list = [-9,-99]"]},{"cell_type":"code","source":["# pass trx_opt\n","trx_replaced, missing_labels_replaced = \\\n","replace_uppr_w_lowr(x=trx_opt,\n","                    missing_labels=missing_labels,\n","                    make_lower=make_lower)\n","\n","print(f'After \"replace_ippr_w_lowr\":\\n\\\n","x-train shape: {trx_replaced.shape}\\nupdated list: {missing_labels_replaced}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RzHk15qDiE7","executionInfo":{"status":"ok","timestamp":1653111277767,"user_tz":360,"elapsed":735,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"90c61c5f-49ed-41b3-9c9d-2a9cc0212516"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["After \"replace_ippr_w_lowr\":\n","x-train shape: (153171, 65)\n","updated list: ['unknown', -9, -99]\n"]}]},{"cell_type":"code","source":["# pass trx_replaced, missing_labels_replaced\n","trx_replaced_merged, missing_labels_merged = \\\n","merge_items(x=trx_replaced,\n","            missing_labels=missing_labels_replaced,\n","            merge_labels=merge_labels,\n","            merge_list=merge_list)\n","\n","# print(f'\\n\\nAfter \"merge_items\":\\nx-train shape:\\\n","# {trx_replaced_merged.shape}\\nmerged list: {missing_labels_merged}')"],"metadata":{"id":"4chq-bD5FIRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pass trx_replaced_merged, missing_labels_merged\n","trx_preproc = \\\n","BuildBinaries(x=trx_replaced_merged,\n","              missing_labels=missing_labels_merged)\n","\n","# print(f'\\n\\nAfter \"BuildBinaries\":\\n\\x-train shape:\\n{trx_preproc.shape}')"],"metadata":{"id":"0XSmMlYxFxw1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Data transforms (num/cat only)"],"metadata":{"id":"xiYwU-1suZ14"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlFknL0YjdWr"},"outputs":[],"source":["# run script for simple feature-selection \n","# function for removing data with high cardinality\n","%run '/content/drive/MyDrive/Data_Science/modules/gtd/CollinearRemover.ipynb'"]},{"cell_type":"markdown","metadata":{"id":"nW5fVnFDj0DT"},"source":["3.0: Build pipelines for standard data transformations, for numeric/categoric training data\n","- _Impute, encode, scale and removing excessive features that are highly collinear_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xaSQ4LoFarNa"},"outputs":[],"source":["#numeric pipe\n","nprep_pipe = Pipeline(\n","    [(\"n_imp\", SimpleImputer(strategy='median')),\n","    ('n_ssscale', MinMaxScaler()),\n","    ('n_collin_remove_90', CollinearRemover(collinear_cutoff=.90))])\n","\n","#categoric pipe\n","cprep_pipe = Pipeline(\n","    [('c_imp', SimpleImputer(strategy='constant',fill_value='missing')),\n","    ('c_hash_enc', ce.HashingEncoder(drop_invariant=True)),\n","    ('c_collin_remove_95', CollinearRemover(collinear_cutoff=.95))])"]},{"cell_type":"markdown","source":["3.1 : Column Selection for pipelines"],"metadata":{"id":"CEvpGS7nzntB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ug4wzxtcat8x"},"outputs":[],"source":["# run script for simple function that uses\n","# `ColumnSelector` transformer to get columns per dtype\n","%run '/content/drive/MyDrive/Data_Science/modules/gtd/select_cols_for_pipe.ipynb'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"6BihR_Jgl6Or","executionInfo":{"status":"ok","timestamp":1653111421935,"user_tz":360,"elapsed":13529,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"9814f2d4-bdd4-4d99-be12-46d5d36e7f48"},"outputs":[{"output_type":"display_data","data":{"text/plain":["mlxtend.feature_selection.column_selector.ColumnSelector"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["mlxtend.feature_selection.column_selector.ColumnSelector"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["mlxtend.feature_selection.column_selector.ColumnSelector"]},"metadata":{}}],"source":["ncols,ccols,tcols = select_cols_for_pipe(trx_opt)\n","\n","# view ColumnSelector objects\n","display(type(ncols),type(ccols),type(tcols))"]},{"cell_type":"markdown","metadata":{"id":"Obe9hdxQm0xC"},"source":["We can use the ColumnSelector-transformers objects above, as is, for an individual step of a pipeline. For simplicity, lets just establish the feature-lists from them for now:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjSaYR8rnIUy","executionInfo":{"status":"ok","timestamp":1653111421936,"user_tz":360,"elapsed":11,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"daa90338-19d3-4afc-af5d-4783dc450e66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total features per dtype:\n","numeric: 31\n","categoric:30\n","text:4\n"]}],"source":["ncols, ccols, tcols = \\\n","list(ncols.cols), list(ccols.cols), list(tcols.cols)\n","\n","print(f'Total features per dtype:\\n\\\n","numeric: {len(ncols)}\\ncategoric:{len(ccols)}\\ntext:{len(tcols)}')"]},{"cell_type":"markdown","metadata":{"id":"5_nz7wQtp5Zy"},"source":["3.2 : Combine numeric/categoric preparation pipelines\n","- _Build/train heterogeneous pipeline on preprocessed data and execute transforms_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sH3s2G8ayZl6","executionInfo":{"status":"ok","timestamp":1653111421937,"user_tz":360,"elapsed":10,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"e266c71f-1707-46e6-867b-0821eec90a44"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(153171, 65)"]},"metadata":{},"execution_count":71}],"source":["trx_opt.shape #reminder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kchCROnDyMZi"},"outputs":[],"source":["#build heterogeneous prep pipeline \n","ncprep_pipe = \\\n","ColumnTransformer([('nprep', nprep_pipe, ncols),\n","                   ('cprep', cprep_pipe, ccols)])\n","\n","# train pipeline,\n","ncprep_pipe.fit(trx_opt)\n","# and prepare numeric/categoric data for ml \n","trx_nc_prepped = ncprep_pipe.transform(trx_opt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1jcUiXsaTDO","executionInfo":{"status":"ok","timestamp":1653111654356,"user_tz":360,"elapsed":30,"user":{"displayName":"John E","userId":"00322197014987294418"}},"outputId":"e3e785fe-acf4-4848-b802-d5575b95c297"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(153171, 37)"]},"metadata":{},"execution_count":73}],"source":["# view results after data transformations (n&c only)\n","trx_nc_prepped.shape"]},{"cell_type":"code","source":["# write dataframe to csv file\n","trx_nc_prepped.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trx_nc_prepped.csv', index=False)"],"metadata":{"id":"8wMer2esXyPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # establish compress options\n","# >>> compression_opts = dict(method='zip',\n","#                         >>> archive_name='trx_nc_prepped.csv')\n","\n","# # write df to zip including options\n","# >>> trx_nc_prepped.to_csv('trx_nc_prepped.zip', index=False,\n","#                       >>> compression=compression_opts)  "],"metadata":{"id":"jHa6YG7eYMTj"},"execution_count":null,"outputs":[]}]}
