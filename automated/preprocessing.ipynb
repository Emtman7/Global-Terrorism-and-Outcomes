{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GLqXSQ7dgSQc",
        "yEn9RT-yoNIa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a revised and re-organized edition of the core (non-trivial) work done in notebook, \"Capstone Project 1 - Data Cleaning\". See also, **\"RunPreproc.py\"** for the automated version of this notebook."
      ],
      "metadata": {
        "id": "RAjVmzdSHhtc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLqXSQ7dgSQc"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22PHePfWhagv"
      },
      "outputs": [],
      "source": [
        "# script for standard imports and reading gtd_df.csv\n",
        "%run '/content/drive/MyDrive/Data_Science/scripts/setup_get_gtd_data.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FszPO709_4Hy",
        "outputId": "66f1129f-e1bb-4a8d-d622-5d5345529c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df\t \n"
          ]
        }
      ],
      "source": [
        "%who DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE72tqV1PAcs",
        "outputId": "f4250dc7-8058-4787-888d-a185ab4fd393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(191464, 135)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x = df.copy()\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEn9RT-yoNIa"
      },
      "source": [
        "# **Step 1: Initial Data Adjustments** \n",
        "(num/cat only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikLyTU2IO6dl"
      },
      "outputs": [],
      "source": [
        "# get all DB admin encoded columns\n",
        "admin_enc_df = \\\n",
        "x.loc[:, [c for c in \n",
        "        [c[:-4] for c in x if '_txt' in c]\n",
        "        if c in x]]\n",
        "\n",
        "#save for comparison or later usage\n",
        "admin_enc_col_list = list(admin_enc_df.columns)\n",
        "# build admin_enc_col_df\n",
        "admin_enc_col_df = x.loc[:, admin_enc_col_list]\n",
        "\n",
        "# do the same w/ lat and long \n",
        "# (add back to dataset later if wanted)\n",
        "lat_long_df=x.loc[:, ['latitude','longitude']]\n",
        "\n",
        "# combine into single column (for dt) create\n",
        "'''to use: .astype('datetime') on \"datetime_col\",\n",
        "need to fill '0' first at all locs'''\n",
        "\n",
        "datetime_col = x['iday'].astype('string') + '-' \\\n",
        "+ x['imonth'].astype('string') + '-' \\\n",
        "+ x['iyear'].astype('string')\n",
        "\n",
        "# remove original day,month,year cols\n",
        "x = x.drop(['iday','imonth','iyear'], axis=1)\n",
        "\n",
        "\"\"\" STEP #1 : Data-Type Adjustments \"\"\"\n",
        "# # Adjust to string Dtypes for text\n",
        "txt_col_list = \\\n",
        "['motive', 'summary','location','propcomment']\n",
        "\n",
        "x.loc[:, txt_col_list] = \\\n",
        "x.loc[:, txt_col_list].astype('string')\n",
        "\n",
        "x['d_m_y'] = datetime_col\n",
        "\n",
        "eventid_related_df = \\\n",
        "x.loc[:, ['eventid', 'related', 'dbsource']]\n",
        "\n",
        "# \"\"\"Get \"cols_for_later\" : \"\"\"\n",
        "cols_for_later = pd.concat(\n",
        "    [x['d_m_y'], lat_long_df, eventid_related_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.0.1 : drop admin encoded cols and additional cols (for later analysis)"
      ],
      "metadata": {
        "id": "wEpuHU7Mwlbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "791XJu2pRwyh"
      },
      "outputs": [],
      "source": [
        "# drop admin encoded cols\n",
        "x = x.drop(list(admin_enc_col_list), axis=1)\n",
        "# Drop additional cols (for later analysis)\n",
        "x = x.drop(list(cols_for_later),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loSMpU7kR_BI",
        "outputId": "7b784f17-a78f-4eb9-caa2-ee6274b9f95c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(191464, 99)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSm7S9VmoWM6"
      },
      "source": [
        "1.0.2 : Get X train/test sets\n",
        "- Because our target/response/dependent feature, `\"success\"`, is of imbalanced nature, we must to maintain the ratio among binary inputs (\"0\"/\"1\") while going about establishing our subsets of train and test sets with [`StratifiedShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn-model-selection-stratifiedshufflesplit).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3MkUgYaOO-A"
      },
      "outputs": [],
      "source": [
        "data = x.copy()\n",
        "\n",
        "SSS = StratifiedShuffleSplit(n_splits=1,\n",
        "                              test_size=0.2,\n",
        "                              random_state=3)\n",
        " \n",
        "for train_idx, test_idx in SSS.split(data, \n",
        "                                     data['success']):\n",
        "    # train and test sets\n",
        "    train_x = data.iloc[train_idx, :]\n",
        "    test_x = data.iloc[test_idx, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IobrtBOpSJqA",
        "outputId": "987bfa6a-5ecb-48e9-f027-24f1f7e07880"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((153171, 99), (38293, 99))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_x.shape, test_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LplC-rkEgCmF"
      },
      "source": [
        "1.0.3 : Remove rows/columns with very high NaN-counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqyLLXeHbfvQ",
        "outputId": "2119090d-918e-4736-9847-35bab7a260c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set (trainx) contains 33 variables with >= 0.95% NaNs\n",
            "\n",
            "\"train_x\" shape after removing columns w/ >= 95% NaNs: (153171, 66)\n"
          ]
        }
      ],
      "source": [
        "#remove rows/columns with very high NaN-counts\n",
        "trx_nan_perc = train_x.isnull().sum() / len(train_x)\n",
        "\n",
        "#condition\n",
        "thresh=0.95\n",
        "thresh_nans = trx_nan_perc>=thresh\n",
        "\n",
        "#subset\n",
        "print(f'Training set (trainx) contains \\\n",
        "{len(trx_nan_perc[thresh_nans])} variables with >= {thresh}% NaNs\\n')\n",
        "\n",
        "# view cols w/ large % Nans\n",
        "high_nan_vars = trx_nan_perc[thresh_nans]\n",
        "high_nan_vars.sort_values(ascending=False)\n",
        "\n",
        "# remove cols w/ high NaN percentages from train set\n",
        "# (save for later for other NaN-alternatives after initial run)\n",
        "train_x.loc[:, list(high_nan_vars.index)]\\\n",
        ".to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trainx_high_nans.csv')\n",
        "\n",
        "# Remove Columns with large percentage of NaNs\n",
        "train_x = train_x.drop(list(high_nan_vars.index),axis=1)\n",
        "\n",
        "# trainx updated\n",
        "print(f'\"train_x\" shape after removing columns w/ >= 95% NaNs: {train_x.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.0.4 : Establish X/y sets\n"
      ],
      "metadata": {
        "id": "0o7I-cDNwCcA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZjfQQBiSR2T"
      },
      "outputs": [],
      "source": [
        "# establish \"target\"\n",
        "trainy = train_x[\"success\"]\n",
        "testy = test_x['success']\n",
        "\n",
        "# and drop from X sets\n",
        "trainx = train_x.drop('success', axis=1)\n",
        "testx = test_x.drop('success', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLMvPqGdSsYI",
        "outputId": "407fca92-0288-4772-a9d2-03718f555745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((153171,), (38293,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# view train/test sets for target\n",
        "trainy.shape, testy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgJaFVCjVezd",
        "outputId": "aee0f572-c4b3-4b50-bd1c-935db35b3fa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((153171, 65), (153171,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#view X-sets after target removal\n",
        "trainx.shape, trainy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bXVf8jtXb4p",
        "outputId": "8bf501c9-8c12-4eac-d219-f47cbeb8d20c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "object     30\n",
              "float64    17\n",
              "int64      14\n",
              "string      4\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 153171 entries, 59924 to 95773\n",
            "Columns: 65 entries, approxdate to INT_ANY\n",
            "dtypes: float64(17), int64(14), object(30), string(4)\n",
            "memory usage: 77.1+ MB\n"
          ]
        }
      ],
      "source": [
        "#before dtype adjustments\n",
        "display(pd.Series(trainx.dtypes).value_counts())\n",
        "trainx.info(verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvDsbzF5o3Fb"
      },
      "source": [
        "1.0.5 : optimize optimize memory/storage (training set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buNpdYqPXA8p"
      },
      "outputs": [],
      "source": [
        "# Reminder to back astype(\"U\") b4 tfidf\n",
        "trx_txt = trainx.select_dtypes(include='string') \n",
        "trx_non_txt = trainx.select_dtypes(exclude='string')\n",
        "# optimize object-types (categorical)\n",
        "trx_cats = trx_non_txt.select_dtypes(object)\n",
        "trx_cats_opt = optimize_objects(trx_cats)\n",
        "# optimize int-types\n",
        "trx_ints = trx_non_txt.select_dtypes(int)\n",
        "trx_ints_opt = optimize_ints(trx_ints)\n",
        "# optimize float-types\n",
        "trx_floats = trx_non_txt.select_dtypes(float)\n",
        "trx_floats_opt = optimize_floats(trx_floats)\n",
        "\n",
        "trx_opt = pd.concat([trx_txt, trx_ints_opt,\n",
        "                     trx_floats_opt, \n",
        "                     trx_cats_opt], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf4E0zSxZAlY",
        "outputId": "eb146924-aef5-476d-9108-781c42c93307"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "object      29\n",
              "float32     17\n",
              "int8        14\n",
              "string       4\n",
              "category     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 153171 entries, 59924 to 95773\n",
            "Columns: 65 entries, location to scite3\n",
            "dtypes: category(1), float32(17), int8(14), object(29), string(4)\n",
            "memory usage: 53.3+ MB\n"
          ]
        }
      ],
      "source": [
        "# trainx after dtype adjustments, \"trx_opt\"\n",
        "display(pd.Series(trx_opt.dtypes).value_counts())\n",
        "trx_opt.info(verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM_4OjX7ZNyz"
      },
      "source": [
        "> _We've decreased the memory usage by about 24MB after dtype-optimization._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyackKJIZij0",
        "outputId": "907e4b32-a525-4dd7-cfe9-eae6934ade11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# without affecting the inherent training data:\n",
        "set(trx_opt)==set(trainx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE: `trainx` == `trx_opt` ... where the latter is simply an optimized (memory/storage) version of the former**"
      ],
      "metadata": {
        "id": "-ME_JXNMsPDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write initial x/y splits, and optimized trainx, \"trx_opt\", to csv:\n",
        "trainx.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trainx.csv',\n",
        "            index=False)\n",
        "trainy.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trainy.csv',\n",
        "            index=False)\n",
        "testx.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/testx.csv',\n",
        "            index=False)\n",
        "testy.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/testy.csv',\n",
        "            index=False)\n",
        "# \"trx_opt\", to csv:\n",
        "trx_opt.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trx_opt.csv',\n",
        "               index=False)"
      ],
      "metadata": {
        "id": "9yqioaZaMZeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GChkIflsz70"
      },
      "source": [
        "# **Step 2 : Preprocessing** - _Expanding on initial data adjustments_\n",
        "\n",
        "2.0.1\n",
        "- `replace_uppr_w_lower`\n",
        "\n",
        "    - correcting database entry errors of missing data\n",
        "\n",
        "2.0.2\n",
        "- `merge_items`\n",
        "\n",
        "    - correcting database entry errors extended: merge \"equivilent\" representation for \"uncertain (i.e.; \"-9\" == \"-99\")\n",
        "\n",
        "2.0.3\n",
        "- `BuildBinaries`\n",
        "\n",
        "    - missing data imputation with indicator or flag variable creation\n",
        "\n",
        "2.0.4\n",
        "- `select_cols_for_pipe`\n",
        "    - creating explicit lists per dtype for sklearn pipeline (next notebook, \"transformations\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move to current directory like magic \n",
        "%cd /content/drive/MyDrive/Data_Science/modules/gtd/\n",
        "\n",
        "# load custom functions \n",
        "%load replace_uppr_w_lowr.ipynb\n",
        "%load merge_items.ipynb\n",
        "%load BuildBinaries.ipynb\n",
        "%load select_cols_for_pipe.ipynb\n",
        "\n",
        "# alternative; w/ full path name:\n",
        "# >>> %run '/content/drive/MyDrive/Data_Science/modules/gtd/replace_uppr_w_lowr.ipynb'\n",
        "# >>> %run '/content/drive/MyDrive/Data_Science/modules/gtd/merge_items.ipynb'\n",
        "# >>> %run '/content/drive/MyDrive/Data_Science/modules/gtd/BuildBinaries.ipynb'\n",
        "# >>> %run '/content/drive/MyDrive/Data_Science/modules/gtd/select_cols_for_pipe.ipynb'"
      ],
      "metadata": {
        "id": "FEGvCkyW955E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEl-9jRYux3r"
      },
      "outputs": [],
      "source": [
        "# determined during initial data exploration\n",
        "missing_labels = ['Unknown',-9,-99]\n",
        "make_lower = 'Unknown'\n",
        "merge_labels = True\n",
        "merge_list = [-9,-99]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0.1 : `replace_uppr_w_lowr`"
      ],
      "metadata": {
        "id": "Jazqr6617HTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pass trx_opt\n",
        "trx_replaced, missing_labels_replaced = \\\n",
        "replace_uppr_w_lowr(x=trx_opt,\n",
        "                    missing_labels=missing_labels,\n",
        "                    make_lower=make_lower)\n",
        "\n",
        "print(f'After \"replace_ippr_w_lowr\":\\n\\\n",
        "x-train shape: {trx_replaced.shape}\\nupdated list: {missing_labels_replaced}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RzHk15qDiE7",
        "outputId": "23627d7b-fd72-42bf-f2df-39b650b75f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After \"replace_ippr_w_lowr\":\n",
            "x-train shape: (153171, 65)\n",
            "updated list: ['unknown', -9, -99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0.2 : `merge_items`"
      ],
      "metadata": {
        "id": "6VqOB_K-7Ejx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pass trx_replaced, missing_labels_replaced\n",
        "trx_replaced_merged, missing_labels_merged = \\\n",
        "merge_items(x=trx_replaced,\n",
        "            missing_labels=missing_labels_replaced,\n",
        "            merge_labels=merge_labels,\n",
        "            merge_list=merge_list)\n",
        "\n",
        "print(f'\\n\\nAfter \"merge_items\":\\nx-train shape:\\\n",
        "{trx_replaced_merged.shape}\\nmerged list: {missing_labels_merged}')"
      ],
      "metadata": {
        "id": "4chq-bD5FIRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0.3 : `BuildBinaries`"
      ],
      "metadata": {
        "id": "YhANr0ke7B1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pass trx_replaced_merged, missing_labels_merged\n",
        "trx_preproc = \\\n",
        "BuildBinaries(x=trx_replaced_merged,\n",
        "              missing_labels=missing_labels_merged)\n",
        "\n",
        "print(f'\\n\\nAfter \"BuildBinaries\":\\n\\x-train shape:\\n{trx_preproc.shape}')"
      ],
      "metadata": {
        "id": "0XSmMlYxFxw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write preprocessed working data-set (num/cat only), \"trx_preproc\", to csv\n",
        "trx_preproc.to_csv('/content/drive/MyDrive/Data_Science/data/gtd/trx_preproc.csv',\n",
        "                   index=False)"
      ],
      "metadata": {
        "id": "27S9TNoIRiu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps"
      ],
      "metadata": {
        "id": "0DmfmCfEcTIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, Establish baseline scores _(see \"baseline scores after preproc.ipynb\")._"
      ],
      "metadata": {
        "id": "V3ChU7WrJXME"
      }
    }
  ]
}
